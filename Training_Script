#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os , random, datetime
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.applications import VGG16, ResNet50V2, EfficientNetV2S
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam

# ========== Path & Para. ==========
data_root = "/data_home/user/2025/username/Python/imagedata"
cls_ok = "OK"
cls_esd = "ESD"
classes = [cls_esd, cls_ok] # Label : esd(0), ok(1)
class_mode = "binary"

img_size = (224, 224) # [Check] (256, 256)으로 size 변경하기, resize (224, 224) 삭제 필요
BATCH = 20 # [Check] 20 -> 16으로 변경
VAL_SPLIT = 0.2
SEED = 42
EPOCHS_STAGE1 = 10 # [Check] 20 -> 10으로 기본값을 변경
EPOCHS_STAGE2 = 10 # [Check] Stage2 미세 튜닝 추가

# ========== Set ROI ==========
ROI_X, ROI_Y = 570, 670
ROI_W, ROI_H = 200, 200
PAD = 28
OUT_H, OUT_W = img_size[0], img_size[1]

ADD_EDGE = True
ADD_DARK = False # closed channel
ADD_DIFF = False # closed channel

AUTOTUNE = tf.data.AUTOTUNE
tf.random.set_seed(SEED)
random.seed(SEED)
np.random.seed(SEED)

# 원본 : (1500, 1500, 3)
# ROI crop : (200, 200, 3) // 좌측 상단 (0, 0) 기준으로 (570, 670)을 crop의 좌상단으로 잡음
# padding(+28) : (256, 256, 3)
# resize : (224, 224, 3)
# Add edge : (224, 224, 4)
# Add dark : (224, 224, 5)
# apply batch : (20, 224, 224, 5)

# ========== File List & Train/Val Split ==========
def list_labeled_files(root):
    p_ok = os.path.join(root, cls_ok)
    p_esd = os.path.join(root, cls_esd)
    ok = [os.path.join(p_ok, f) for f in os.listdir(p_ok) if f.lower().endswith(".jpg", ".jpeg", ".png")]
    esd = [os.path.join(p_esd, f) for f in os.listdir(p_esd) if f.lower().endswith(".jpg", ".jpeg", ".png")]
    ok.sort(); esd.sort()
    return [(p, 1) for p in ok] + [(p, 0) for p in esd]
    # [(filepath, label), ... ] tuple들을 모은 list
    # label -> OK : 1, ESD : 0으로 부여

all_pairs = list_labeled_files(data_root) # data_root를 읽고 tuple List 생성
random.Random(SEED).shuffle(all_pairs) # tuple List의 원소들을 shuffle

def stratified_split(pairs, val_ratio = 0.2):
    by_label = {0: [], 1: []}
    for p, l in pairs: by_label[l].append((p, l)) # lower case of Alphabet "L"
    train, val = [], []
    for l, bucket in by_label.items():
        n = len(bucket); nv = int(round(n * val_ratio))
        val.extend(bucket[:nv]); train.extend(bucket[nv:])
    random.Random(SEED).shuffle(train); random.Random(SEED).shuffle(val)
    return train, val
    # train, val 둘 다 (filepath, label) tuple을 나눠 갖는 list

train_list, val_list = stratified_split(all_pairs, VAL_SPLIT)

print(f"Train : {len(train_list)} Val : {len(val_list)}")
print("class_indices : ", {cls_esd : 0, cls_ok : 1})

# ========== Preprocessing (TF Calculation) ==========
def decode_image(path):
    img = tf.io.read_file(path)
    img = tf.io.decode_jpeg(img, channels = 3) # JPG -> (1500, 1500, 3) tensor(uint8)
    img = tf.image.convert_image_dtype(img, tf.float32) # (1500, 1500, 3) (float32)
    return img
    # (1500, 1500, 3) tensor (float32)

def crop_roi(img):
    h = tf.shape(img)[0]; w = tf.shape(img)[1] # h : 1500, w : 1500
    x0 = tf.clip_by_value(ROI_X - PAD, 0, w) # (570 - 28, 0, 1500)
    y0 = tf.clip_by_value(ROI_Y - PAD, 0, h) # (670 - 28, 0, 1500)
    x1 = tf.clip_by_value(ROI_X + ROI_W + PAD, 0, w) # (570 + 200 + 28, 0, 1500)
    y1 = tf.clip_by_value(ROI_Y + ROI_H + PAD, 0, h) # (670 + 200 + 28, 0, 1500)
    roi = img[y0:y1, x0:x1] # img[642:898, 542:798] -> (256, 256, 3) cropped
    roi = tf.image.resize(roi, (OUT_H, OUT_W), method = "bilinear") # (224, 224, 3)
    return roi
    # (224, 224, 3) tensor (float32) pixel : 0~255

def per_image_std(x):
    return tf.image.per_image_standardization(x)
    # (224, 224, 3) tensor (float32) pixel : -1 ~ +1 normalized

def sobel_mag(x01):
    x4 = tf.expand_dims(x01, axis = 0) # (1, 224, 224, 3)
    sob = tf.image.sobel_edges(x4) # (1, 224, 224, 3, 2), 마지막 축[dx, dy]은 gradient
    sob = tf.squeeze(sob, axis = 0) # (224, 224, 3, 2)
    gx, gy = sob[..., 0], sob[..., 1] # 둘 다 (224, 224, 3)
    mag = tf.sqrt(gx * gx + gy * gy) # (224, 224, 3)
    mag = tf.reduce_mean(mag, axis = -1, keepdims = True) # 채널 방향 Avg (224, 224, 1)
    return mag
    # (224, 224, 1) : gradient magnitude, 보통 0 이상이며 "가장자리"일수록 큰 값을 나타냄

def darkness(x01):
    gray = tf.image.rgb_to_grayscale(x01) # (224, 224, 1)
    return 1.0 - gray
    # (224, 224, 1), gray : 어두울수록 값 증가, 밝을수록 값 감소

def normalize01(x):
    mn = tf.reduce_min(x); mx = tf.reduce_max(x)
    return (x - mn) / (mx - mn + 1e-6)
    # (224, 224, 3) tensor (float32) pixel : 0 ~ 1 normalized

def build_feature(path, label):
    img = decode_image(path) # 이미지(JPG)를 읽고 (1500, 1500, 3) tensor로 변환 (uint8)
    img = crop_roi(img) # ROI 설정에 따라 tensor를 잘라냄 (224, 224, 3) (float32)
    x = per_image_std(img) # 0~255 값을 -1 ~ +1 부근으로 정규화 (224, 224, 3) (float32)

    # x01 : SubChannel Calculation
    x01 = normalize01(x) # 0~1 범위로 다시 정규화 (224, 224, 3) (float32)

    feats = [x01]

    if ADD_EDGE:
        feats.append(sobel_mag(x01)) # +1 Channel
        # (224, 224, 1) sobel_mag Channel 추가

    if ADD_DARK:
        feats.append(darkness(x01)) # +1 Channel
        # (224, 224, 1) darkness Channel 추가

    feat = tf.concat(feats, axis = -1) # 5 Channel
    # (224, 224, 3) + (224, 224, 1) + (224, 224, 1) = (224, 224, 5)

    # if ADD_DIFF: ->> option

    return feat, tf.cast(label, tf.float32)
    # feat : (224, 224, 5) (float32) 0 ~ 1 사이의 값들
    # label : () float32 0 or 1의 값들

def make_ds(pairs, batch = BATCH, shuffle = True):
    paths = [p for p,_ in pairs] # (filepath, label)에서 filepath(...JPG)
    labels = [l for _,l in pairs] # (filepath, label)에서 label(0 or 1)

    ds = tf.data.Dataset.from_tensor_slices((paths, labels))
    # 두 list를 from_tensor_slices가 tensor로 묶음. datatype : tf.data.Dataset
    # list를 tensor로 묶은 객체

    if shuffle:
        ds = ds.shuffle(len(pairs), seed = SEED, reshuffle_each_iteration = True)

    ds = ds.map(build_feature, num_parallel_calls = AUTOTUNE)
    # [ feat : (224, 224, 5)(tensor), label : ()(scalar, 0.0 or 1.0의 값임) ]

    def aug(x, y):
        x = tf.image.random_flip_left_right(x)
        x = tf.image.random_brightness(x, max_delta = 0.05)
        x = tf.image.random_contrast(x, 0.9, 1.1)
        return x, y
        # feat : (224, 224, 5) 증강 적용됨, y는 label을 의미하고 별다른 처리를 안 함

    if shuffle:
        ds = ds.map(aug, num_parallel_calls = AUTOTUNE)

    ds = ds.batch(batch).prefetch(AUTOTUNE)
    # x(feat) : (20, 224, 224, 5) -> train은 shuffle=True라서 aug도 진행
    # y(label) : (20, )              val은 shuffle=False라서 aug를 skip

    return ds

def history_to_df(history):
    d = history.history
    df = pd.DataFrame(d)
    df.insert(0, "epoch", range(1, len(df) + 1))
    return df

train_ds = make_ds(train_list, shuffle = True)
val_ds = make_ds(val_list, shuffle = False)

# ========== Class weight ==========
# Label : ESD(0), OK(1)

counts = np.bincount([l for _, l in train_list], minlength = 2)
N = counts.sum(); K = 2

class_weight = {i: float(N) / (K * counts[i]) for i in range(K)}

print("class_weight : ", class_weight)

# ========== Channel Mapper (N -> 3), Backbone ==========
sample_x, _ = next(iter(train_ds.take(1))) # train_ds의 원소는 (20, 224, 224, 5)
in_ch = int(sample_x.shape[-1]) # input_channel : 5
print("Input channels : ", in_ch)

inp = layers.Input(shape = (img_size[0], img_size[1], in_ch), name = "multi_input")
# input_shape : (224, 224, 5)

# Channel mapper
x = layers.Conv2D(16, 1, padding = "same", activation = "relu", name = "ch_mapper_16")(inp)
# (224, 224, 5) -> (224, 224, 16)
x = layers.Conv2D(3, 1, padding = "same", activation = None, name = "ch_mapper_3")(x)
# (224, 224, 16) -> (224, 224, 3)
x = layers.Lambda(lambda t: preprocess_input(t * 255.0), name = "vgg_preproc")(x)
# 0 ~ 1 범위의 값에 255 곱해서 0~255 범위로 복원. preprocess_input() 적용
# (224, 224, 3)

# Backbone
base = VGG16(weights = "imagenet", include_top = False, input_shape = (img_size[0], img_size[1], 3))
y = base(x)
# (224, 224, 3) -> (7, 7, 512)

# Custom Head
h = layers.GlobalAveragePooling2D()(y) # (7, 7, 512) -> (512, )
h = layers.Dropout(0.3)(h)
h = layers.Dense(128, activation = "relu")(h) # (512, ) -> (128, )
h = layers.Dropout(0.3)(h)
out = layers.Dense(1, activation = "sigmoid")(h) # (128, ) -> 스칼라(0 : ESD ~ 1 : OK)

model = models.Model(inputs = inp, outputs = out)
# Input : (224, 224, 5)
# Channel Mapper : 5 -> 3
# Backbone : (224, 224, 3) -> feature maps
# Custom Head : 0 ~ 1 classification

# ========== Backbone Freeze, ChannelMapper & Head only Train ==========
for l in base.layers:
    l.trainable = False

model.get_layer("ch_mapper_16").trainable = True
model.get_layer("ch_mapper_3").trainable = True

# ========== Compile & Callbacks ==========
model.compile(
    optimizer = Adam(1e-3),
    loss = "binary_crossentropy",
    metrics = ["accuracy"]
)

work_dir = data_root
ckpt_path = os.path.join(work_dir, "ImageClassifier_Model_VGG16.keras”)

callbacks = [
    ModelCheckpoint(ckpt_path, monitor = "val_accuracy", save_best_only = True, mode = "max", verbose = 1),
    EarlyStopping(monitor = "val_accuracy", patience = 5, mode = "max", restore_best_weights = True),
    ReduceLROnPlateau(monitor = "val_loss", factor = 0.5, patience = 2, verbose = 1, min_lr = 1e-6)
]

# ========== Execute Training ==========
history1 = model.fit(
    train_ds,
    epochs = EPOCHS_STAGE1,
    validation_data = val_ds,
    class_weight = class_weight,
    callbacks = callbacks
)

df_hist = history_to_df(history1)
save_dir = data_root
os.makedirs(save_dir, exist_ok = True)
ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
csv_path = os.path.join(save_dir, f"training_log_{ts}.csv")

df_hist.to_csv(csv_path, index = False, encoding = "utf-8-sig")
print("Saved : ", csv_path)
df_hist.head()

final_path = os.path.join(work_dir, “ImageClassifier_Model_VGG16_final.keras”)
model.save(final_path)
print("Final Model Saved : ", final_path)

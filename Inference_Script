#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
VGG16 채널 매퍼(5→3) 기반 이진분류 모델(.keras/.h5) 추론 스크립트
- 학습 파이프라인과 동일한 전처리(개별 함수)로 (224,224,5) 텐서 생성
- 파일명 오름차순으로 추론 후 CSV [Filename, Result] 저장

필수: TF 2.x (eager), numpy, pandas
주의: 모델 내부에 vgg16 preprocess_input Lambda가 있으므로, 여기서는 호출하지 않음
"""

import os
import argparse
from pathlib import Path
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import load_model

# -----------------------------
# 전역 파라미터 (학습과 동일)
# -----------------------------
IMG_SIZE = (224, 224)
ROI_X, ROI_Y = 570, 670
ROI_W, ROI_H = 200, 200
PAD = 28

# 확장자: 필요시 png 추가 가능
VALID_EXTS = {".jpg", ".jpeg", ".JPG", ".JPEG"}

# -----------------------------
# 전처리 함수들 (개별 함수로 분리)
# -----------------------------
def decode_image_tf(path_str: str) -> tf.Tensor:
    """bytes -> RGB float32 [0,1], (H,W,3)"""
    b = tf.io.read_file(path_str)
    img = tf.io.decode_jpeg(b, channels=3)  # uint8
    img = tf.image.convert_image_dtype(img, tf.float32)  # [0,1]
    return img  # (H,W,3) float32

def crop_roi_tf(img: tf.Tensor) -> tf.Tensor:
    """ROI(+PAD) 크롭 후 (224,224) 리사이즈, float32 [0,1]"""
    h = tf.shape(img)[0]
    w = tf.shape(img)[1]
    x0 = tf.clip_by_value(ROI_X - PAD, 0, w)
    y0 = tf.clip_by_value(ROI_Y - PAD, 0, h)
    x1 = tf.clip_by_value(ROI_X + ROI_W + PAD, 0, w)
    y1 = tf.clip_by_value(ROI_Y + ROI_H + PAD, 0, h)
    roi = img[y0:y1, x0:x1]  # (~,~,3)
    roi = tf.image.resize(roi, IMG_SIZE, method="bilinear")  # (224,224,3)
    return roi

def per_image_std_tf(x: tf.Tensor) -> tf.Tensor:
    """(224,224,3) → 표준화 (per-image standardization)"""
    return tf.image.per_image_standardization(x)

def normalize01_tf(x: tf.Tensor) -> tf.Tensor:
    """[-1,+1] 부근 값을 [0,1]로 재정규화"""
    x_min = tf.reduce_min(x)
    x_max = tf.reduce_max(x)
    # 분모 0 방지
    x = (x - x_min) / tf.maximum(x_max - x_min, 1e-6)
    return x

def sobel_mag_tf(x01: tf.Tensor) -> tf.Tensor:
    """x01: (224,224,3) [0,1] → 소벨 Edge magnitude 1채널 (224,224,1)"""
    x4 = tf.expand_dims(x01, axis=0)                   # (1,224,224,3)
    sob = tf.image.sobel_edges(x4)                     # (1,224,224,3,2)
    sob = tf.squeeze(sob, axis=0)                      # (224,224,3,2)
    gx, gy = sob[..., 0], sob[..., 1]                  # (224,224,3)
    mag = tf.sqrt(gx * gx + gy * gy)                   # (224,224,3)
    mag = tf.reduce_mean(mag, axis=-1, keepdims=True)  # (224,224,1)
    return mag

def darkness_tf(x01: tf.Tensor) -> tf.Tensor:
    """x01: (224,224,3) [0,1] → darkness 1채널 (224,224,1)"""
    gray = tf.image.rgb_to_grayscale(x01)  # (224,224,1) [0,1]
    return 1.0 - gray

def to_five_channels_tf(img_path: str) -> tf.Tensor:
    """
    단일 이미지 경로 → (224,224,5) float32
    (decode → crop_roi → per_image_std → normalize01 → sobel → darkness → concat)
    """
    x = decode_image_tf(img_path)          # (H,W,3) [0,1]
    x = crop_roi_tf(x)                     # (224,224,3) [0,1]
    x = per_image_std_tf(x)                # (224,224,3) ~[-1,+1]
    x01 = normalize01_tf(x)                # (224,224,3) [0,1]
    e1 = sobel_mag_tf(x01)                 # (224,224,1)
    d1 = darkness_tf(x01)                  # (224,224,1)
    x5 = tf.concat([x01, e1, d1], axis=-1) # (224,224,5)
    return x5

def build_batch_tensor(paths):
    """
    파일 경로 리스트 → (N,224,224,5) float32 텐서
    (증강 없음, preprocess_input 없음)
    """
    tensors = [to_five_channels_tf(str(p)) for p in paths]
    batch = tf.stack(tensors, axis=0)  # (N,224,224,5)
    return batch

def iter_batches(seq, batch_size):
    for i in range(0, len(seq), batch_size):
        yield seq[i:i+batch_size]

# -----------------------------
# 메인
# -----------------------------
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--images", default="/username/Python/images",
                        help="입력 이미지 폴더 경로")
    parser.add_argument("--model", default="/username/Python/ImageClassifier_Model_VGG16.keras",
                        help="학습 모델(.keras/.h5) 경로")
    parser.add_argument("--out_csv", default="/username/Python/pred_results.csv",
                        help="출력 CSV 경로")
    parser.add_argument("--batch", type=int, default=64, help="배치 크기")
    parser.add_argument("--thresh", type=float, default=0.5,
                        help="OK 판정 임계값 (sigmoid 확률)")
    args = parser.parse_args()

    images_dir = Path(args.images)
    assert images_dir.is_dir(), f"이미지 폴더가 존재하지 않습니다: {images_dir}"

    # 파일명 오름차순 수집
    files = [p for p in images_dir.iterdir() if p.is_file() and p.suffix in VALID_EXTS]
    files.sort(key=lambda p: p.name)
    if not files:
        raise SystemExit(f"[ERROR] 유효한 JPG 파일이 없습니다: {images_dir}")

    # 모델 로드
    model = load_model(args.model, compile=False)

    # 입력 채널 확인 (안전장치)
    try:
        in_ch = int(model.input_shape[-1])
    except Exception:
        in_ch = None
    if in_ch is not None and in_ch != 5:
        raise SystemExit(f"[ERROR] 모델 입력 채널이 {in_ch}로 감지되었습니다. (예상: 5)")

    # 예측
    basenames = [p.name for p in files]
    preds = []

    for chunk in iter_batches(files, args.batch):
        batch_x = build_batch_tensor(chunk)                 # (N,224,224,5) float32
        prob_ok = model.predict(batch_x, verbose=0).ravel() # (N,)
        preds.extend(prob_ok.tolist())

    preds = np.array(preds, dtype=np.float32)
    labels = np.where(preds >= args.thresh, "OK", "ESD")

    # CSV 저장
    df_out = pd.DataFrame({
        "Filename": basenames,
        "Result": labels
    })
    df_out.to_csv(args.out_csv, index=False, encoding="utf-8-sig")

    print(f"[DONE] Saved CSV → {args.out_csv}")
    print(f"Total images: {len(basenames)} | OK: {(labels=='OK').sum()} | ESD: {(labels=='ESD').sum()}")

if __name__ == "__main__":
    # 성능(쓰레드) 관련 설정은 필요시 추가 가능
    tf.config.threading.set_intra_op_parallelism_threads(0)
    tf.config.threading.set_inter_op_parallelism_threads(0)
    main()
